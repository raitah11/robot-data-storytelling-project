# robot-data-storytelling-project

Project Description
This project pilots a public-facing, interactive exhibit using the Misty II robot to narrate real-world civic data through expressive storytelling. By integrating large language models (LLMs) with Misty’s facial animations, light cues, arm gestures, and voice synthesis, we aim to transform complex NYC Open Data into short, emotionally engaging narratives about housing justice, public health, and environmental equity. These robot-delivered stories will be showcased at the Fall 2025 NYC PIT pop-up event, organized by the CUNY PIT Lab, to explore how embodiment and interactivity influence public trust, understanding, and engagement with public interest technology (PIT).

After each story, Misty will initiate a brief dialogue with the participant, followed by a short survey assessing their perception of the robot’s tone, clarity, and trustworthiness. With participant consent, we will collect audiovisual data to measure attention and emotional engagement. This multimodal pilot will provide foundational insights into how embodied AI can make civic data more accessible and emotionally resonant for the public.

Goals and Significance
The project aims to (1) prototype a data storytelling system on Misty II that translates public datasets into expressive narratives, (2) evaluate how robotic delivery influences public engagement, trust, and understanding, and (3) develop early design guidelines for civic-facing social robots. In a moment where civic trust in data and institutions is critical, this project offers a novel way to make civic data more relatable and engaging, inviting the public into meaningful dialogue about justice, equity, and the role of technology in public life.

Research Questions and Approach
To guide this investigation, the project is framed around the following research questions, which explore the relationship between robot-delivered data storytelling and public trust, engagement, and understanding.

How do users emotionally and cognitively respond to robot-delivered stories drawn from civic datasets?
What design factors (voice, tone, gestures, pacing) influence perceived trust, engagement, and understanding?
Can social robots serve as accessible, low-barrier interfaces for public interest technology and civic learning?

We will use an LLM such as GPT-4 to generate accessible, emotionally engaging narratives from 2-3 NYC Open Data datasets on topics like housing affordability, asthma rates in public housing, or tree canopy coverage by borough. Each dataset will be distilled into short, thematic stories that highlight inequities, trends, or civic challenges in everyday language. For example, a story might describe how uneven tree coverage across neighborhoods contributes to heat vulnerability during summer months, or how eviction filings disproportionately impact certain zip codes.

These narratives will be scripted and synchronized with expressive behaviors on the Misty II robot, using its built-in tools for facial animation, RGB LED signaling, arm gestures, and voice output. We will vary Misty’s tone, pacing, and gestures depending on the narrative tone (e.g., slower, calmer speech and blue light for stories about housing instability; faster, more animated delivery and yellow light for positive data trends). Misty’s behaviors will be refined through internal pilot testing to ensure clarity, expressivity, and affective alignment with each story.

The robot will be deployed primarily at the Fall 2025 NYC PIT Pop-Up Event, a high-visibility public exhibition hosted by the CUNY PIT Lab to demonstrate public interest technology in action. Visitors to the event will encounter Misty at an interactive station featuring a small kiosk, visual displays of the underlying datasets, and signage introducing the research.

As each visitor approaches, Misty will greet them and deliver one of the pre-scripted data stories using speech, motion, and light cues. Afterward, the robot will ask one or two conversational questions (e.g., “Did anything surprise you about that story?”, “Would you trust a robot to explain public data like this?”), encouraging brief reflection or dialogue. Participants will then be invited to complete a short digital survey on a tablet or their phones, evaluating the robot’s tone, clarity, trustworthiness, and the perceived relevance of the story.
